{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download commands if needed\n",
    "#!pip install jaro-winkler\n",
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_lg\n",
    "\n",
    "# load base libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import pickle\n",
    "import jaro\n",
    "from itertools import combinations\n",
    "\n",
    "# load spacy libraries \n",
    "import spacy \n",
    "from spacy import displacy\n",
    "import en_core_web_lg\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "1. For each news feed, identify Organization, People and location\n",
    "2. For recognized Organizations, identify repeating entities using a string distance measure\n",
    "3. For each unique orgnization, obtain frequency, surface the top 2 recognized organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt startup for M&A DUNS only\n",
    "devdata_multilabel = pd.read_excel('devdata_narrower_businessevents.xlsx') \n",
    "devdata_multilabel = devdata_multilabel[devdata_multilabel['label'] == 'acquisitions-mergers-and-takeovers']\n",
    "devdata_multilabel = devdata_multilabel.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "devdata_multilabel = pd.read_excel('devdata_narrower_businessevents.xlsx') \n",
    "devdata_multilabel = devdata_multilabel[devdata_multilabel['label'] != 'obituaries'] # remove \"obituaries\" category\n",
    "devdata_multilabel = devdata_multilabel.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "# only include body text -> headlines confuse NER as it is case sesitive\n",
    "# remove common punctuation (comma, period) and possesives ('s)\n",
    "#devdata_multilabel['text'] = devdata_multilabel['headline'] + '. ' + devdata_multilabel['body'] # combine headline and body of text\n",
    "devdata_multilabel['text'] = devdata_multilabel['body'] # only use body\n",
    "devdata_multilabel['text'] = devdata_multilabel['text'].replace('\\n',' ', regex=True).replace('\\t',' ', regex=True) # remove line breaker\n",
    "devdata_multilabel['text'] = devdata_multilabel['text'].replace(',','', regex=True).replace('\\.','', regex=True)  # remove punctuation\n",
    "devdata_multilabel['text'] = devdata_multilabel['text'].replace('\\'s','', regex=True).replace('\\'','', regex=True) # remove posesives \n",
    "devdata_multilabel['text'] = devdata_multilabel['text'].replace('\\'','', regex=True).replace(':',' ', regex=True)\n",
    "devdata_multilabel = devdata_multilabel[['label','text']] # keep only two columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Entity Recognition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ner fuction for single news article\n",
    "def ner(newsfeed):\n",
    "    \n",
    "    # run spacy nlp fuction\n",
    "    news_nlp = nlp(newsfeed)\n",
    "    \n",
    "    # extract identified organizational entities\n",
    "    recognized_org = []\n",
    "    for entity in news_nlp.ents:\n",
    "        label = entity.label_\n",
    "        if label == 'ORG': recognized_org.append(entity.text)\n",
    "        else: continue\n",
    "    \n",
    "    # fuzzy-string comparission\n",
    "    pairs = list(combinations(recognized_org,2))\n",
    "    repeating = []\n",
    "    for i in pairs:\n",
    "         if jaro.jaro_winkler_metric(i[0].lower(), i[1].lower()) > 0.8:\n",
    "            if len(i[0]) < len(i[1]): i = [i[1], i[0]] # want longest version in position 0\n",
    "            if i[1] != i[0]: repeating.append(i) # only keep non-same pairs\n",
    "\n",
    "    # fix repeating entities\n",
    "    for i in repeating: newsfeed = newsfeed.replace(i[0],i[1])\n",
    "    \n",
    "    # save identified entities\n",
    "    news_nlp = nlp(newsfeed)\n",
    "    recognized_org = []\n",
    "    recognized_gpe = []\n",
    "    recognized_date = []\n",
    "    recognized_people = []\n",
    "\n",
    "    for entity in news_nlp.ents:\n",
    "        label = entity.label_\n",
    "        if label == 'ORG': recognized_org.append(entity.text)\n",
    "        elif label == 'DATE': recognized_date.append(entity.text)\n",
    "        elif label == 'GPE': recognized_gpe.append(entity.text)\n",
    "        elif label == 'PERSON': recognized_people.append(entity.text)\n",
    "        else: continue\n",
    "    \n",
    "    # output identified entities\n",
    "    newsfeed_entities = pd.DataFrame([[recognized_org], [recognized_gpe], [recognized_date], [recognized_people]])\n",
    "    \n",
    "    # handel no organizational entities\n",
    "    if len(recognized_org) > 0:\n",
    "        # count unique organizations frequency\n",
    "        wordfreq = []\n",
    "        for org in recognized_org: wordfreq.append(newsfeed.count(org))\n",
    "        \n",
    "        # find top 2 most frequent organizations\n",
    "        orgfreq = pd.DataFrame(zip(recognized_org, wordfreq))\n",
    "        orgfreq = orgfreq.rename(columns={0:'entity',1:'count'})\n",
    "        orgfreq = orgfreq.sort_values(by='count', ascending=False)\n",
    "        orgfreq = orgfreq.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        # output top 2 most frequent organizations\n",
    "        try: top2 = [(orgfreq.iloc[0,0], orgfreq.iloc[0,1]), (orgfreq.iloc[1,0], orgfreq.iloc[1,1])]\n",
    "        except: top2 = [(orgfreq.iloc[0,0], orgfreq.iloc[0,1])] # handel if only one organization\n",
    "        newsfeed_entities = newsfeed_entities.append([[top2]])\n",
    "    else:\n",
    "        newsfeed_entities = newsfeed_entities.append([])\n",
    "    \n",
    "    # output final result\n",
    "    newsfeed_entities = newsfeed_entities.reset_index(drop=True)\n",
    "    return newsfeed_entities, repeating\n",
    "\n",
    "newsfeed = devdata_multilabel['text'].iloc[1]\n",
    "#newsfeed_entities, repeating = ner(newsfeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "# run ner function on all news articles (17432 articles total)\n",
    "entities = pd.DataFrame()\n",
    "repeats = pd.DataFrame()\n",
    "i = 0\n",
    "for feed in devdata_multilabel['text'][:200]:\n",
    "    newsfeed_entities, repeating = ner(feed)\n",
    "    entities = entities.append(newsfeed_entities.T)\n",
    "    repeats = repeats.append(repeating)\n",
    "    print(i)\n",
    "    i += 1\n",
    "    \n",
    "# clean output datafame\n",
    "entities = entities.rename(columns={0:'Organization',1:'Geolocation',2:'Datetime',3:'Person',4:'Top2'})\n",
    "entities = entities.reset_index(drop=True)\n",
    "repeats = repeats.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization</th>\n",
       "      <th>Geolocation</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Person</th>\n",
       "      <th>Top2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[RALEIGH NC, Rifiniti]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[July 10 2019, today, today]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(RALEIGH NC, 1), (Rifiniti, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Premium Transportation Logistics, Senior Mana...</td>\n",
       "      <td>[TOLEDO]</td>\n",
       "      <td>[July 1 2019, today]</td>\n",
       "      <td>[Jeff Curry, Keith Avery, Brad Kelley]</td>\n",
       "      <td>[(PTL, 4), (Premium Transportation Logistics, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ANNAPOLIS Md, Chesapeake Eye Care, Vision Inn...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[June 24 2019]</td>\n",
       "      <td>[Michael Dunn]</td>\n",
       "      <td>[(Vision Innovation Partners, 3), (ANNAPOLIS M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[GREENWICH Conn, Southfield Capital, Ntiva Inc...</td>\n",
       "      <td>[Chicago, Illinois]</td>\n",
       "      <td>[July 30 2019, today]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(GREENWICH Conn, 1), (Southfield Capital, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Great Wave, Salesforce, Ksquare, Glenn Kohner...</td>\n",
       "      <td>[DALLAS]</td>\n",
       "      <td>[20 2019]</td>\n",
       "      <td>[Ksquare]</td>\n",
       "      <td>[(Ksquare, 3), (Great Wave, 2)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>[Jazz Pharmaceuticals plc, Nasdaq  JAZZ, Redx ...</td>\n",
       "      <td>[DUBLIN]</td>\n",
       "      <td>[July 10 2019, today]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Redx, 3), (RAF, 2)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>[GREENWICH Conn, Blue Harbour Group LP, BCA, B...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[June 26 2019, 2018, today]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(BCA, 2), (GREENWICH Conn, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>[BEDFORD Mass, Great Hill Partners]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[June 26 2019, today]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(BEDFORD Mass, 1), (Great Hill Partners, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>[Archcon Architecture, Archcon Design Build, D...</td>\n",
       "      <td>[SAN ANTONIO, Texas]</td>\n",
       "      <td>[July 25 2019]</td>\n",
       "      <td>[Cheryl Cole]</td>\n",
       "      <td>[(DALLENBACH, 2), (Archcon Architecture, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>[Southern Harvest Insurance]</td>\n",
       "      <td>[HUNTINGTON BEACH, Calif, US, Georgia, Alabama]</td>\n",
       "      <td>[July 10 2019, today]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Southern Harvest Insurance, 1)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Organization  \\\n",
       "0                               [RALEIGH NC, Rifiniti]   \n",
       "1    [Premium Transportation Logistics, Senior Mana...   \n",
       "2    [ANNAPOLIS Md, Chesapeake Eye Care, Vision Inn...   \n",
       "3    [GREENWICH Conn, Southfield Capital, Ntiva Inc...   \n",
       "4    [Great Wave, Salesforce, Ksquare, Glenn Kohner...   \n",
       "..                                                 ...   \n",
       "195  [Jazz Pharmaceuticals plc, Nasdaq  JAZZ, Redx ...   \n",
       "196  [GREENWICH Conn, Blue Harbour Group LP, BCA, B...   \n",
       "197                [BEDFORD Mass, Great Hill Partners]   \n",
       "198  [Archcon Architecture, Archcon Design Build, D...   \n",
       "199                       [Southern Harvest Insurance]   \n",
       "\n",
       "                                         Geolocation  \\\n",
       "0                                                 []   \n",
       "1                                           [TOLEDO]   \n",
       "2                                                 []   \n",
       "3                                [Chicago, Illinois]   \n",
       "4                                           [DALLAS]   \n",
       "..                                               ...   \n",
       "195                                         [DUBLIN]   \n",
       "196                                               []   \n",
       "197                                               []   \n",
       "198                             [SAN ANTONIO, Texas]   \n",
       "199  [HUNTINGTON BEACH, Calif, US, Georgia, Alabama]   \n",
       "\n",
       "                         Datetime                                  Person  \\\n",
       "0    [July 10 2019, today, today]                                      []   \n",
       "1            [July 1 2019, today]  [Jeff Curry, Keith Avery, Brad Kelley]   \n",
       "2                  [June 24 2019]                          [Michael Dunn]   \n",
       "3           [July 30 2019, today]                                      []   \n",
       "4                       [20 2019]                               [Ksquare]   \n",
       "..                            ...                                     ...   \n",
       "195         [July 10 2019, today]                                      []   \n",
       "196   [June 26 2019, 2018, today]                                      []   \n",
       "197         [June 26 2019, today]                                      []   \n",
       "198                [July 25 2019]                           [Cheryl Cole]   \n",
       "199         [July 10 2019, today]                                      []   \n",
       "\n",
       "                                                  Top2  \n",
       "0                     [(RALEIGH NC, 1), (Rifiniti, 1)]  \n",
       "1    [(PTL, 4), (Premium Transportation Logistics, 1)]  \n",
       "2    [(Vision Innovation Partners, 3), (ANNAPOLIS M...  \n",
       "3       [(GREENWICH Conn, 1), (Southfield Capital, 1)]  \n",
       "4                      [(Ksquare, 3), (Great Wave, 2)]  \n",
       "..                                                 ...  \n",
       "195                              [(Redx, 3), (RAF, 2)]  \n",
       "196                    [(BCA, 2), (GREENWICH Conn, 1)]  \n",
       "197      [(BEDFORD Mass, 1), (Great Hill Partners, 1)]  \n",
       "198       [(DALLENBACH, 2), (Archcon Architecture, 1)]  \n",
       "199                  [(Southern Harvest Insurance, 1)]  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique orgs\n",
    "allOrgs = pd.DataFrame()\n",
    "for orgs in entities['Organization'][:]:\n",
    "    allOrgs = allOrgs.append(orgs)\n",
    "\n",
    "# process all orgs for duplicates\n",
    "allOrgs = allOrgs.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle repeats and alternative namings\n",
    "for i in range(allOrgs.shape[0]): # for each unique organization\n",
    "    org = allOrgs.iloc[i,0]\n",
    "    for j in range(repeats.shape[0]): # for each similar organization\n",
    "        repeat = repeats.iloc[j,0]\n",
    "        if org == repeat: # are they the same?\n",
    "            allOrgs.iloc[i,0] = repeats.iloc[j,1] # repalce with shortened, equivilant org\n",
    "            #print(i, org, j, repeats.iloc[j,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# huge loop - only run if really needed - catches similar orgs across articles\n",
    "# fuzzy-string comparission for allOrgs\n",
    "check_repeats = False\n",
    "if check_repeats:\n",
    "    allOrgs = allOrgs.drop_duplicates().reset_index(drop=True)\n",
    "    pairs = list(combinations(list(allOrgs[0]),2))\n",
    "    repeating = []\n",
    "    for i in pairs:\n",
    "         if jaro.jaro_winkler_metric(i[0].lower(), i[1].lower()) > 0.8:\n",
    "                if len(i[0]) < len(i[1]): i = [i[1], i[0]] # want longest version in position 0\n",
    "                repeating.append(i)\n",
    "    repeating = pd.DataFrame(repeating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DUNS</th>\n",
       "      <th>short_entity_name</th>\n",
       "      <th>alt_name_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RALEIGH NC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Rifiniti</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Premium Transportation Logistics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Senior Management Team</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PTL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>Sierra MCC</td>\n",
       "      <td>[Sierra Income Corporation, Sierra MCC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>608</td>\n",
       "      <td>Spark Power Corp</td>\n",
       "      <td>[Spark Power Group Inc, Spark Power Corp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>609</td>\n",
       "      <td>VEON Holdings</td>\n",
       "      <td>[VEON Holdings BV, VEON Holdings]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>610</td>\n",
       "      <td>Wacoal America Inc</td>\n",
       "      <td>[Wacoal International Corporation, Wacoal Amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>611</td>\n",
       "      <td>the Bonos Soberanos</td>\n",
       "      <td>[the \"Bonos Soberanos\", the Bonos Soberanos]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DUNS                 short_entity_name  \\\n",
       "0       0                        RALEIGH NC   \n",
       "1       1                          Rifiniti   \n",
       "2       2  Premium Transportation Logistics   \n",
       "3       3            Senior Management Team   \n",
       "4       4                               PTL   \n",
       "..    ...                               ...   \n",
       "607   607                        Sierra MCC   \n",
       "608   608                  Spark Power Corp   \n",
       "609   609                     VEON Holdings   \n",
       "610   610                Wacoal America Inc   \n",
       "611   611               the Bonos Soberanos   \n",
       "\n",
       "                                         alt_name_list  \n",
       "0                                                  NaN  \n",
       "1                                                  NaN  \n",
       "2                                                  NaN  \n",
       "3                                                  NaN  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "607            [Sierra Income Corporation, Sierra MCC]  \n",
       "608          [Spark Power Group Inc, Spark Power Corp]  \n",
       "609                  [VEON Holdings BV, VEON Holdings]  \n",
       "610  [Wacoal International Corporation, Wacoal Amer...  \n",
       "611       [the \"Bonos Soberanos\", the Bonos Soberanos]  \n",
       "\n",
       "[612 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define aggregation function\n",
    "def agg_fun(x):\n",
    "    agg = []\n",
    "    for i in x: agg += [i]\n",
    "    return agg\n",
    "\n",
    "# aggregate similar organization entities\n",
    "if check_repeats: repeat_df = repeats.append(repeating).reset_index(drop=True)\n",
    "else: repeat_df = repeats.copy()\n",
    "repeat_dic = repeat_df.groupby(1).agg(agg_fun).reset_index() \n",
    "\n",
    "# process all orgs for new duplicates and merge with alt name df\n",
    "allOrgs = allOrgs.drop_duplicates().reset_index(drop=True)\n",
    "unqOrg = allOrgs.merge(repeat_dic, left_on=0, right_on=1, how='outer')\n",
    "unqOrg = unqOrg.drop(columns=[1,'0_x'])\n",
    "unqOrg = unqOrg.reset_index().rename(columns={'index':'DUNS','key_0':'short_entity_name','0_y':'alt_name_list'}) \n",
    "unqOrg['alt_name_list'] = unqOrg['alt_name_list'] + unqOrg['short_entity_name'].apply(lambda x: [x])   \n",
    "unqOrg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to save as DUNS number file\n",
    "unqOrg.to_csv('mna_duns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
